{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ DailyFlash Offer Generator - Model Training\n",
    "\n",
    "This notebook fine-tunes a GPT2 model to generate structured JSON offers from raw promotional text.\n",
    "\n",
    "## Overview\n",
    "1. Setup and installation\n",
    "2. Data loading and preprocessing\n",
    "3. Model configuration\n",
    "4. Training\n",
    "5. Saving the model\n",
    "6. Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Installation\n",
    "\n",
    "First, let's install the necessary packages and configure Google Drive for saving the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install required libraries\n",
    "!pip install transformers datasets accelerate torch evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Mount Google Drive for saving model\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directory to save model\n",
    "import os\n",
    "os.makedirs('/content/drive/MyDrive/offer_generator_model', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Upload dataset to Colab\n",
    "from google.colab import files\n",
    "uploaded = files.upload()  # Upload your offer_dataset.jsonl file here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Preprocess Data\n",
    "\n",
    "We'll use the HuggingFace datasets library to load our JSONL data and prepare it for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load dataset\n",
    "data = []\n",
    "with open('offer_dataset.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# Print sample to verify data\n",
    "print(dataset[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load tokenizer and model\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configure tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Split into training and validation\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "print(f\"Training size: {len(split_dataset['train'])}\")\n",
    "print(f\"Validation size: {len(split_dataset['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure Training\n",
    "\n",
    "We'll set up the training parameters and data collator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configure model for training\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/offer_generator_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Data collator for language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # We're doing causal language modeling, not masked language modeling\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the Model\n",
    "\n",
    "Now we'll train the model using the Trainer API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Save the Model\n",
    "\n",
    "Let's save the trained model to Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the model\n",
    "save_directory = \"/content/drive/MyDrive/offer_generator_model/final_model\"\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model saved to {save_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test the Model\n",
    "\n",
    "Let's generate some offers using the trained model to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function for generating offers\n",
    "def generate_offer(input_text, model=model, tokenizer=tokenizer):\n",
    "    prompt = f\"Input: {input_text}\\nOutput:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "    \n",
    "    # Generate output\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_length=512,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    \n",
    "    # Decode and clean up the output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract just the JSON part\n",
    "    if \"Output:\" in generated_text:\n",
    "        generated_text = generated_text.split(\"Output:\")[1].strip()\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test the model with some examples\n",
    "test_inputs = [\n",
    "    \"50% off on all electronics at TechMart until Dec 25. Shop now at www.techmart.com\",\n",
    "    \"Buy 2 get 1 free on shirts at ABC Store, Lucknow. Call: +919876543210\",\n",
    "    \"New test case: Flash sale on all vegetables at FreshMart, Mumbai. Valid today only.\"\n",
    "]\n",
    "\n",
    "for test_input in test_inputs:\n",
    "    print(f\"Input: {test_input}\")\n",
    "    result = generate_offer(test_input)\n",
    "    print(f\"Output: {result}\")\n",
    "    print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Model (Optional)\n",
    "\n",
    "If you want to download the model files directly to your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Zip the model directory for download\n",
    "!zip -r /content/offer_generator_model.zip /content/drive/MyDrive/offer_generator_model/final_model\n",
    "files.download('/content/offer_generator_model.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Congratulations!\n",
    "\n",
    "You've successfully trained a model that can generate structured JSON offers from raw promotional text. This model can now be used in your inference script and Gradio UI."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
